{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TensorFlow with GPU",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tMce8muBqXQP"
      },
      "source": [
        "# Tensorflow with GPU\n",
        "\n",
        "This notebook provides an introduction to computing on a [GPU](https://cloud.google.com/gpu) in Colab. In this notebook you will connect to a GPU, and then run some basic TensorFlow operations on both the CPU and a GPU, observing the speedup provided by using the GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oM_8ELnJq_wd"
      },
      "source": [
        "## Enabling and testing the GPU\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Edit→Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll confirm that we can connect to the GPU with tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sXnDmXR7RDr2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "abb56286-8721-4e06-cdbe-1f590c3d46e2"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v3fE7KmKRDsH"
      },
      "source": [
        "## Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y04m-jvKRDsJ",
        "outputId": "6781653e-8ee5-403a-920b-96a2bee724de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "3.778669743000137\n",
            "GPU (s):\n",
            "0.06611503299996002\n",
            "GPU speedup over CPU: 57x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC9hMXnIddKW",
        "colab_type": "code",
        "outputId": "84df29fc-66be-4500-f7db-5fe8465c41d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import sys, os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw3QU1Blg6wA",
        "colab_type": "code",
        "outputId": "791c5fba-c59b-47ac-b957-5eca37498037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAzttlOyds3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv('gdrive/My Drive/fer2013.csv')\n",
        "X_train,train_y,X_test,test_y=[],[],[],[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqW9IyVWd1uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for index, row in df.iterrows():\n",
        "    val=row['pixels'].split(\" \")\n",
        "    try:\n",
        "        if 'Training' in row['Usage']:\n",
        "           X_train.append(np.array(val,'float32'))\n",
        "           train_y.append(row['emotion'])\n",
        "        elif 'PublicTest' in row['Usage']:\n",
        "           X_test.append(np.array(val,'float32'))\n",
        "           test_y.append(row['emotion'])\n",
        "    except:\n",
        "        print(f\"error occured at index :{index} and row:{row}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SSS6fmR7YH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_features = 64\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 200\n",
        "width, height = 48, 48"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJJQMulxm2OR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.array(X_train,'float32')\n",
        "train_y = np.array(train_y,'float32')\n",
        "X_test = np.array(X_test,'float32')\n",
        "test_y = np.array(test_y,'float32')\n",
        "\n",
        "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
        "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNkBpS7QnBAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalizing data between oand 1\n",
        "X_train -= np.mean(X_train, axis=0)\n",
        "X_train /= np.std(X_train, axis=0)\n",
        "\n",
        "X_test -= np.mean(X_test, axis=0)\n",
        "X_test /= np.std(X_test, axis=0)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjMl196fnESM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSaicJiS6-Ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
        "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#2nd convolution layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#3rd convolution layer\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6GZrhO57BeG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fully connected neural networks\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(num_labels, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prCElaO87EXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compliling the model\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc9y01Nu7G3n",
        "colab_type": "code",
        "outputId": "def3a1e3-bb48-4c67-dd86-24730a7a17ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Training the model\n",
        "model.fit(X_train, train_y,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, test_y),\n",
        "          shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 28709 samples, validate on 3589 samples\n",
            "Epoch 1/200\n",
            "28709/28709 [==============================] - 7s 249us/step - loss: 1.7287 - accuracy: 0.2943 - val_loss: 1.5425 - val_accuracy: 0.3912\n",
            "Epoch 2/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 1.5064 - accuracy: 0.4063 - val_loss: 1.3982 - val_accuracy: 0.4595\n",
            "Epoch 3/200\n",
            "28709/28709 [==============================] - 7s 240us/step - loss: 1.4063 - accuracy: 0.4539 - val_loss: 1.3257 - val_accuracy: 0.4893\n",
            "Epoch 4/200\n",
            "28709/28709 [==============================] - 7s 237us/step - loss: 1.3439 - accuracy: 0.4792 - val_loss: 1.2976 - val_accuracy: 0.5046\n",
            "Epoch 5/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 1.3006 - accuracy: 0.5007 - val_loss: 1.2381 - val_accuracy: 0.5241\n",
            "Epoch 6/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 1.2608 - accuracy: 0.5158 - val_loss: 1.2298 - val_accuracy: 0.5294\n",
            "Epoch 7/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 1.2345 - accuracy: 0.5295 - val_loss: 1.2099 - val_accuracy: 0.5366\n",
            "Epoch 8/200\n",
            "28709/28709 [==============================] - 7s 237us/step - loss: 1.2067 - accuracy: 0.5390 - val_loss: 1.1948 - val_accuracy: 0.5475\n",
            "Epoch 9/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 1.1835 - accuracy: 0.5475 - val_loss: 1.1798 - val_accuracy: 0.5444\n",
            "Epoch 10/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 1.1601 - accuracy: 0.5573 - val_loss: 1.1735 - val_accuracy: 0.5475\n",
            "Epoch 11/200\n",
            "28709/28709 [==============================] - 7s 237us/step - loss: 1.1381 - accuracy: 0.5632 - val_loss: 1.1737 - val_accuracy: 0.5514\n",
            "Epoch 12/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 1.1183 - accuracy: 0.5707 - val_loss: 1.1712 - val_accuracy: 0.5628\n",
            "Epoch 13/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 1.1030 - accuracy: 0.5793 - val_loss: 1.1476 - val_accuracy: 0.5684\n",
            "Epoch 14/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 1.0869 - accuracy: 0.5852 - val_loss: 1.1495 - val_accuracy: 0.5684\n",
            "Epoch 15/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 1.0681 - accuracy: 0.5901 - val_loss: 1.1627 - val_accuracy: 0.5612\n",
            "Epoch 16/200\n",
            "28709/28709 [==============================] - 7s 237us/step - loss: 1.0514 - accuracy: 0.5993 - val_loss: 1.1525 - val_accuracy: 0.5575\n",
            "Epoch 17/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 1.0365 - accuracy: 0.6021 - val_loss: 1.1552 - val_accuracy: 0.5634\n",
            "Epoch 18/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 1.0169 - accuracy: 0.6132 - val_loss: 1.1513 - val_accuracy: 0.5651\n",
            "Epoch 19/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 1.0047 - accuracy: 0.6167 - val_loss: 1.1644 - val_accuracy: 0.5690\n",
            "Epoch 20/200\n",
            "28709/28709 [==============================] - 7s 243us/step - loss: 0.9985 - accuracy: 0.6191 - val_loss: 1.1556 - val_accuracy: 0.5667\n",
            "Epoch 21/200\n",
            "28709/28709 [==============================] - 7s 238us/step - loss: 0.9829 - accuracy: 0.6230 - val_loss: 1.1590 - val_accuracy: 0.5659\n",
            "Epoch 22/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.9664 - accuracy: 0.6284 - val_loss: 1.1473 - val_accuracy: 0.5717\n",
            "Epoch 23/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.9497 - accuracy: 0.6375 - val_loss: 1.1721 - val_accuracy: 0.5743\n",
            "Epoch 24/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.9396 - accuracy: 0.6406 - val_loss: 1.1797 - val_accuracy: 0.5614\n",
            "Epoch 25/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.9295 - accuracy: 0.6475 - val_loss: 1.1684 - val_accuracy: 0.5659\n",
            "Epoch 26/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.9043 - accuracy: 0.6539 - val_loss: 1.1651 - val_accuracy: 0.5840\n",
            "Epoch 27/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.9064 - accuracy: 0.6535 - val_loss: 1.1637 - val_accuracy: 0.5756\n",
            "Epoch 28/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.8877 - accuracy: 0.6623 - val_loss: 1.1885 - val_accuracy: 0.5715\n",
            "Epoch 29/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.8750 - accuracy: 0.6695 - val_loss: 1.1947 - val_accuracy: 0.5840\n",
            "Epoch 30/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.8665 - accuracy: 0.6701 - val_loss: 1.1971 - val_accuracy: 0.5653\n",
            "Epoch 31/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.8565 - accuracy: 0.6759 - val_loss: 1.2172 - val_accuracy: 0.5743\n",
            "Epoch 32/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.8350 - accuracy: 0.6833 - val_loss: 1.2151 - val_accuracy: 0.5904\n",
            "Epoch 33/200\n",
            "28709/28709 [==============================] - 7s 233us/step - loss: 0.8400 - accuracy: 0.6816 - val_loss: 1.1637 - val_accuracy: 0.5885\n",
            "Epoch 34/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.8244 - accuracy: 0.6867 - val_loss: 1.1974 - val_accuracy: 0.5829\n",
            "Epoch 35/200\n",
            "28709/28709 [==============================] - 7s 233us/step - loss: 0.8051 - accuracy: 0.6965 - val_loss: 1.2084 - val_accuracy: 0.5784\n",
            "Epoch 36/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.8007 - accuracy: 0.6955 - val_loss: 1.2372 - val_accuracy: 0.5862\n",
            "Epoch 37/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.7978 - accuracy: 0.7000 - val_loss: 1.2143 - val_accuracy: 0.5748\n",
            "Epoch 38/200\n",
            "28709/28709 [==============================] - 7s 233us/step - loss: 0.7832 - accuracy: 0.7039 - val_loss: 1.2137 - val_accuracy: 0.5743\n",
            "Epoch 39/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.7700 - accuracy: 0.7109 - val_loss: 1.2246 - val_accuracy: 0.5745\n",
            "Epoch 40/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.7653 - accuracy: 0.7137 - val_loss: 1.2461 - val_accuracy: 0.5795\n",
            "Epoch 41/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.7534 - accuracy: 0.7194 - val_loss: 1.2482 - val_accuracy: 0.5768\n",
            "Epoch 42/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.7454 - accuracy: 0.7176 - val_loss: 1.2698 - val_accuracy: 0.5695\n",
            "Epoch 43/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.7317 - accuracy: 0.7248 - val_loss: 1.2718 - val_accuracy: 0.5754\n",
            "Epoch 44/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.7298 - accuracy: 0.7276 - val_loss: 1.2742 - val_accuracy: 0.5701\n",
            "Epoch 45/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.7137 - accuracy: 0.7325 - val_loss: 1.2608 - val_accuracy: 0.5698\n",
            "Epoch 46/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.7088 - accuracy: 0.7333 - val_loss: 1.2615 - val_accuracy: 0.5787\n",
            "Epoch 47/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.7004 - accuracy: 0.7362 - val_loss: 1.2811 - val_accuracy: 0.5737\n",
            "Epoch 48/200\n",
            "28709/28709 [==============================] - 7s 238us/step - loss: 0.7013 - accuracy: 0.7362 - val_loss: 1.3122 - val_accuracy: 0.5729\n",
            "Epoch 49/200\n",
            "28709/28709 [==============================] - 7s 238us/step - loss: 0.6875 - accuracy: 0.7419 - val_loss: 1.3235 - val_accuracy: 0.5712\n",
            "Epoch 50/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.6837 - accuracy: 0.7437 - val_loss: 1.2764 - val_accuracy: 0.5834\n",
            "Epoch 51/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.6757 - accuracy: 0.7465 - val_loss: 1.2917 - val_accuracy: 0.5876\n",
            "Epoch 52/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.6601 - accuracy: 0.7517 - val_loss: 1.3071 - val_accuracy: 0.5823\n",
            "Epoch 53/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.6567 - accuracy: 0.7550 - val_loss: 1.3453 - val_accuracy: 0.5807\n",
            "Epoch 54/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.6527 - accuracy: 0.7554 - val_loss: 1.3380 - val_accuracy: 0.5801\n",
            "Epoch 55/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.6393 - accuracy: 0.7635 - val_loss: 1.3587 - val_accuracy: 0.5687\n",
            "Epoch 56/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.6272 - accuracy: 0.7700 - val_loss: 1.3236 - val_accuracy: 0.5840\n",
            "Epoch 57/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.6214 - accuracy: 0.7708 - val_loss: 1.3875 - val_accuracy: 0.5768\n",
            "Epoch 58/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.6153 - accuracy: 0.7737 - val_loss: 1.3698 - val_accuracy: 0.5776\n",
            "Epoch 59/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.6167 - accuracy: 0.7728 - val_loss: 1.3583 - val_accuracy: 0.5704\n",
            "Epoch 60/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.6094 - accuracy: 0.7763 - val_loss: 1.3762 - val_accuracy: 0.5773\n",
            "Epoch 61/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.6083 - accuracy: 0.7758 - val_loss: 1.3754 - val_accuracy: 0.5676\n",
            "Epoch 62/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.6013 - accuracy: 0.7831 - val_loss: 1.3956 - val_accuracy: 0.5832\n",
            "Epoch 63/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.5953 - accuracy: 0.7837 - val_loss: 1.3719 - val_accuracy: 0.5821\n",
            "Epoch 64/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.5818 - accuracy: 0.7846 - val_loss: 1.3738 - val_accuracy: 0.5834\n",
            "Epoch 65/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.5745 - accuracy: 0.7900 - val_loss: 1.4495 - val_accuracy: 0.5804\n",
            "Epoch 66/200\n",
            "28709/28709 [==============================] - 7s 243us/step - loss: 0.5836 - accuracy: 0.7862 - val_loss: 1.4409 - val_accuracy: 0.5740\n",
            "Epoch 67/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.5633 - accuracy: 0.7921 - val_loss: 1.4821 - val_accuracy: 0.5737\n",
            "Epoch 68/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.5575 - accuracy: 0.7976 - val_loss: 1.4412 - val_accuracy: 0.5773\n",
            "Epoch 69/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.5575 - accuracy: 0.7958 - val_loss: 1.4292 - val_accuracy: 0.5779\n",
            "Epoch 70/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.5597 - accuracy: 0.7955 - val_loss: 1.4552 - val_accuracy: 0.5729\n",
            "Epoch 71/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.5482 - accuracy: 0.7989 - val_loss: 1.4871 - val_accuracy: 0.5684\n",
            "Epoch 72/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.5514 - accuracy: 0.8005 - val_loss: 1.4107 - val_accuracy: 0.5784\n",
            "Epoch 73/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.5418 - accuracy: 0.8005 - val_loss: 1.4182 - val_accuracy: 0.5773\n",
            "Epoch 74/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.5308 - accuracy: 0.8056 - val_loss: 1.4394 - val_accuracy: 0.5692\n",
            "Epoch 75/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.5326 - accuracy: 0.8061 - val_loss: 1.4481 - val_accuracy: 0.5782\n",
            "Epoch 76/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.5390 - accuracy: 0.8059 - val_loss: 1.4285 - val_accuracy: 0.5776\n",
            "Epoch 77/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.5181 - accuracy: 0.8091 - val_loss: 1.4917 - val_accuracy: 0.5729\n",
            "Epoch 78/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.5320 - accuracy: 0.8078 - val_loss: 1.4824 - val_accuracy: 0.5701\n",
            "Epoch 79/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.5131 - accuracy: 0.8152 - val_loss: 1.5054 - val_accuracy: 0.5773\n",
            "Epoch 80/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.5225 - accuracy: 0.8102 - val_loss: 1.4435 - val_accuracy: 0.5709\n",
            "Epoch 81/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.5049 - accuracy: 0.8155 - val_loss: 1.5585 - val_accuracy: 0.5798\n",
            "Epoch 82/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.5121 - accuracy: 0.8164 - val_loss: 1.4770 - val_accuracy: 0.5779\n",
            "Epoch 83/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.4940 - accuracy: 0.8217 - val_loss: 1.4725 - val_accuracy: 0.5793\n",
            "Epoch 84/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.4898 - accuracy: 0.8240 - val_loss: 1.5117 - val_accuracy: 0.5779\n",
            "Epoch 85/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.4842 - accuracy: 0.8252 - val_loss: 1.5668 - val_accuracy: 0.5809\n",
            "Epoch 86/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.4958 - accuracy: 0.8223 - val_loss: 1.5384 - val_accuracy: 0.5756\n",
            "Epoch 87/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.4895 - accuracy: 0.8268 - val_loss: 1.4925 - val_accuracy: 0.5759\n",
            "Epoch 88/200\n",
            "28709/28709 [==============================] - 7s 233us/step - loss: 0.4803 - accuracy: 0.8268 - val_loss: 1.5732 - val_accuracy: 0.5687\n",
            "Epoch 89/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.4821 - accuracy: 0.8258 - val_loss: 1.6393 - val_accuracy: 0.5589\n",
            "Epoch 90/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.4599 - accuracy: 0.8354 - val_loss: 1.5555 - val_accuracy: 0.5793\n",
            "Epoch 91/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.4693 - accuracy: 0.8336 - val_loss: 1.5959 - val_accuracy: 0.5709\n",
            "Epoch 92/200\n",
            "28709/28709 [==============================] - 7s 233us/step - loss: 0.4732 - accuracy: 0.8287 - val_loss: 1.5530 - val_accuracy: 0.5678\n",
            "Epoch 93/200\n",
            "28709/28709 [==============================] - 7s 233us/step - loss: 0.4672 - accuracy: 0.8353 - val_loss: 1.5444 - val_accuracy: 0.5698\n",
            "Epoch 94/200\n",
            "28709/28709 [==============================] - 7s 239us/step - loss: 0.4628 - accuracy: 0.8351 - val_loss: 1.5946 - val_accuracy: 0.5645\n",
            "Epoch 95/200\n",
            "28709/28709 [==============================] - 7s 233us/step - loss: 0.4608 - accuracy: 0.8348 - val_loss: 1.6117 - val_accuracy: 0.5743\n",
            "Epoch 96/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.4459 - accuracy: 0.8420 - val_loss: 1.6590 - val_accuracy: 0.5676\n",
            "Epoch 97/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.4513 - accuracy: 0.8389 - val_loss: 1.5912 - val_accuracy: 0.5704\n",
            "Epoch 98/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.4548 - accuracy: 0.8406 - val_loss: 1.5783 - val_accuracy: 0.5759\n",
            "Epoch 99/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.4416 - accuracy: 0.8440 - val_loss: 1.6072 - val_accuracy: 0.5790\n",
            "Epoch 100/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.4397 - accuracy: 0.8436 - val_loss: 1.5974 - val_accuracy: 0.5770\n",
            "Epoch 101/200\n",
            "28709/28709 [==============================] - 7s 233us/step - loss: 0.4483 - accuracy: 0.8398 - val_loss: 1.6798 - val_accuracy: 0.5726\n",
            "Epoch 102/200\n",
            "28709/28709 [==============================] - 7s 233us/step - loss: 0.4371 - accuracy: 0.8415 - val_loss: 1.6081 - val_accuracy: 0.5698\n",
            "Epoch 103/200\n",
            "28709/28709 [==============================] - 7s 233us/step - loss: 0.4484 - accuracy: 0.8420 - val_loss: 1.5876 - val_accuracy: 0.5829\n",
            "Epoch 104/200\n",
            "28709/28709 [==============================] - 7s 233us/step - loss: 0.4384 - accuracy: 0.8452 - val_loss: 1.6434 - val_accuracy: 0.5801\n",
            "Epoch 105/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.4358 - accuracy: 0.8466 - val_loss: 1.5857 - val_accuracy: 0.5821\n",
            "Epoch 106/200\n",
            "28709/28709 [==============================] - 7s 233us/step - loss: 0.4283 - accuracy: 0.8494 - val_loss: 1.6274 - val_accuracy: 0.5879\n",
            "Epoch 107/200\n",
            "28709/28709 [==============================] - 7s 233us/step - loss: 0.4308 - accuracy: 0.8497 - val_loss: 1.6233 - val_accuracy: 0.5737\n",
            "Epoch 108/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.4157 - accuracy: 0.8526 - val_loss: 1.6171 - val_accuracy: 0.5807\n",
            "Epoch 109/200\n",
            "28709/28709 [==============================] - 7s 233us/step - loss: 0.4250 - accuracy: 0.8474 - val_loss: 1.6229 - val_accuracy: 0.5776\n",
            "Epoch 110/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.4362 - accuracy: 0.8474 - val_loss: 1.6090 - val_accuracy: 0.5712\n",
            "Epoch 111/200\n",
            "28709/28709 [==============================] - 7s 233us/step - loss: 0.4226 - accuracy: 0.8518 - val_loss: 1.7249 - val_accuracy: 0.5790\n",
            "Epoch 112/200\n",
            "28709/28709 [==============================] - 7s 241us/step - loss: 0.4159 - accuracy: 0.8522 - val_loss: 1.6651 - val_accuracy: 0.5818\n",
            "Epoch 113/200\n",
            "28709/28709 [==============================] - 7s 237us/step - loss: 0.4152 - accuracy: 0.8536 - val_loss: 1.6507 - val_accuracy: 0.5751\n",
            "Epoch 114/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.4123 - accuracy: 0.8547 - val_loss: 1.6109 - val_accuracy: 0.5765\n",
            "Epoch 115/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3995 - accuracy: 0.8593 - val_loss: 1.6152 - val_accuracy: 0.5804\n",
            "Epoch 116/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.4104 - accuracy: 0.8568 - val_loss: 1.6222 - val_accuracy: 0.5779\n",
            "Epoch 117/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.4124 - accuracy: 0.8562 - val_loss: 1.6695 - val_accuracy: 0.5709\n",
            "Epoch 118/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.4138 - accuracy: 0.8550 - val_loss: 1.6675 - val_accuracy: 0.5729\n",
            "Epoch 119/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.4138 - accuracy: 0.8560 - val_loss: 1.7164 - val_accuracy: 0.5737\n",
            "Epoch 120/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.4074 - accuracy: 0.8575 - val_loss: 1.6742 - val_accuracy: 0.5648\n",
            "Epoch 121/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.4099 - accuracy: 0.8574 - val_loss: 1.7058 - val_accuracy: 0.5812\n",
            "Epoch 122/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3854 - accuracy: 0.8657 - val_loss: 1.7525 - val_accuracy: 0.5726\n",
            "Epoch 123/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.4027 - accuracy: 0.8596 - val_loss: 1.7681 - val_accuracy: 0.5715\n",
            "Epoch 124/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.4030 - accuracy: 0.8611 - val_loss: 1.6924 - val_accuracy: 0.5773\n",
            "Epoch 125/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3841 - accuracy: 0.8649 - val_loss: 1.7108 - val_accuracy: 0.5670\n",
            "Epoch 126/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3921 - accuracy: 0.8641 - val_loss: 1.7095 - val_accuracy: 0.5715\n",
            "Epoch 127/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3884 - accuracy: 0.8637 - val_loss: 1.7851 - val_accuracy: 0.5639\n",
            "Epoch 128/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3902 - accuracy: 0.8626 - val_loss: 1.8173 - val_accuracy: 0.5665\n",
            "Epoch 129/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3965 - accuracy: 0.8631 - val_loss: 1.7709 - val_accuracy: 0.5701\n",
            "Epoch 130/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3675 - accuracy: 0.8717 - val_loss: 1.7516 - val_accuracy: 0.5734\n",
            "Epoch 131/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3944 - accuracy: 0.8645 - val_loss: 1.7297 - val_accuracy: 0.5712\n",
            "Epoch 132/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3757 - accuracy: 0.8708 - val_loss: 1.6625 - val_accuracy: 0.5731\n",
            "Epoch 133/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3765 - accuracy: 0.8686 - val_loss: 1.7175 - val_accuracy: 0.5756\n",
            "Epoch 134/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3797 - accuracy: 0.8689 - val_loss: 1.6452 - val_accuracy: 0.5704\n",
            "Epoch 135/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3880 - accuracy: 0.8654 - val_loss: 1.7344 - val_accuracy: 0.5673\n",
            "Epoch 136/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3867 - accuracy: 0.8662 - val_loss: 1.6872 - val_accuracy: 0.5829\n",
            "Epoch 137/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3634 - accuracy: 0.8757 - val_loss: 1.7358 - val_accuracy: 0.5687\n",
            "Epoch 138/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3751 - accuracy: 0.8711 - val_loss: 1.7161 - val_accuracy: 0.5748\n",
            "Epoch 139/200\n",
            "28709/28709 [==============================] - 7s 239us/step - loss: 0.3888 - accuracy: 0.8674 - val_loss: 1.6644 - val_accuracy: 0.5648\n",
            "Epoch 140/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3642 - accuracy: 0.8764 - val_loss: 1.7464 - val_accuracy: 0.5692\n",
            "Epoch 141/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3752 - accuracy: 0.8717 - val_loss: 1.7616 - val_accuracy: 0.5754\n",
            "Epoch 142/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3652 - accuracy: 0.8758 - val_loss: 1.7595 - val_accuracy: 0.5623\n",
            "Epoch 143/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3614 - accuracy: 0.8765 - val_loss: 1.7569 - val_accuracy: 0.5776\n",
            "Epoch 144/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3723 - accuracy: 0.8727 - val_loss: 1.8143 - val_accuracy: 0.5795\n",
            "Epoch 145/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3578 - accuracy: 0.8783 - val_loss: 1.7450 - val_accuracy: 0.5715\n",
            "Epoch 146/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.3600 - accuracy: 0.8774 - val_loss: 1.7767 - val_accuracy: 0.5798\n",
            "Epoch 147/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3657 - accuracy: 0.8767 - val_loss: 1.8277 - val_accuracy: 0.5631\n",
            "Epoch 148/200\n",
            "28709/28709 [==============================] - 7s 233us/step - loss: 0.3535 - accuracy: 0.8775 - val_loss: 1.8184 - val_accuracy: 0.5648\n",
            "Epoch 149/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3599 - accuracy: 0.8766 - val_loss: 1.8084 - val_accuracy: 0.5701\n",
            "Epoch 150/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3593 - accuracy: 0.8766 - val_loss: 1.8646 - val_accuracy: 0.5756\n",
            "Epoch 151/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3662 - accuracy: 0.8748 - val_loss: 1.7831 - val_accuracy: 0.5706\n",
            "Epoch 152/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3584 - accuracy: 0.8772 - val_loss: 1.7770 - val_accuracy: 0.5628\n",
            "Epoch 153/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3543 - accuracy: 0.8779 - val_loss: 1.7369 - val_accuracy: 0.5690\n",
            "Epoch 154/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3443 - accuracy: 0.8807 - val_loss: 1.8077 - val_accuracy: 0.5759\n",
            "Epoch 155/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3512 - accuracy: 0.8824 - val_loss: 1.9163 - val_accuracy: 0.5612\n",
            "Epoch 156/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3474 - accuracy: 0.8829 - val_loss: 1.7751 - val_accuracy: 0.5762\n",
            "Epoch 157/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3546 - accuracy: 0.8793 - val_loss: 1.7694 - val_accuracy: 0.5712\n",
            "Epoch 158/200\n",
            "28709/28709 [==============================] - 7s 241us/step - loss: 0.3543 - accuracy: 0.8789 - val_loss: 1.7916 - val_accuracy: 0.5628\n",
            "Epoch 159/200\n",
            "28709/28709 [==============================] - 7s 240us/step - loss: 0.3418 - accuracy: 0.8835 - val_loss: 1.8423 - val_accuracy: 0.5784\n",
            "Epoch 160/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3387 - accuracy: 0.8839 - val_loss: 1.7830 - val_accuracy: 0.5706\n",
            "Epoch 161/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3494 - accuracy: 0.8806 - val_loss: 1.8535 - val_accuracy: 0.5773\n",
            "Epoch 162/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3423 - accuracy: 0.8830 - val_loss: 1.8223 - val_accuracy: 0.5656\n",
            "Epoch 163/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3400 - accuracy: 0.8835 - val_loss: 1.8715 - val_accuracy: 0.5717\n",
            "Epoch 164/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3514 - accuracy: 0.8808 - val_loss: 1.7959 - val_accuracy: 0.5745\n",
            "Epoch 165/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3505 - accuracy: 0.8834 - val_loss: 1.7885 - val_accuracy: 0.5687\n",
            "Epoch 166/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3271 - accuracy: 0.8908 - val_loss: 1.8835 - val_accuracy: 0.5634\n",
            "Epoch 167/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3436 - accuracy: 0.8840 - val_loss: 1.8003 - val_accuracy: 0.5768\n",
            "Epoch 168/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3353 - accuracy: 0.8856 - val_loss: 1.8351 - val_accuracy: 0.5745\n",
            "Epoch 169/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3359 - accuracy: 0.8878 - val_loss: 1.8979 - val_accuracy: 0.5634\n",
            "Epoch 170/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3248 - accuracy: 0.8898 - val_loss: 1.8514 - val_accuracy: 0.5759\n",
            "Epoch 171/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3310 - accuracy: 0.8866 - val_loss: 1.8746 - val_accuracy: 0.5639\n",
            "Epoch 172/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3304 - accuracy: 0.8869 - val_loss: 1.8976 - val_accuracy: 0.5731\n",
            "Epoch 173/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3290 - accuracy: 0.8890 - val_loss: 1.9833 - val_accuracy: 0.5709\n",
            "Epoch 174/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3388 - accuracy: 0.8854 - val_loss: 1.8346 - val_accuracy: 0.5729\n",
            "Epoch 175/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3439 - accuracy: 0.8858 - val_loss: 1.8541 - val_accuracy: 0.5612\n",
            "Epoch 176/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.3380 - accuracy: 0.8874 - val_loss: 1.7896 - val_accuracy: 0.5737\n",
            "Epoch 177/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3371 - accuracy: 0.8862 - val_loss: 1.8450 - val_accuracy: 0.5642\n",
            "Epoch 178/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.3326 - accuracy: 0.8886 - val_loss: 1.8116 - val_accuracy: 0.5737\n",
            "Epoch 179/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.3289 - accuracy: 0.8875 - val_loss: 1.8881 - val_accuracy: 0.5701\n",
            "Epoch 180/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3304 - accuracy: 0.8891 - val_loss: 1.8590 - val_accuracy: 0.5706\n",
            "Epoch 181/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.3261 - accuracy: 0.8890 - val_loss: 1.8992 - val_accuracy: 0.5720\n",
            "Epoch 182/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3237 - accuracy: 0.8918 - val_loss: 1.8764 - val_accuracy: 0.5681\n",
            "Epoch 183/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.3201 - accuracy: 0.8918 - val_loss: 1.9038 - val_accuracy: 0.5709\n",
            "Epoch 184/200\n",
            "28709/28709 [==============================] - 7s 237us/step - loss: 0.3224 - accuracy: 0.8912 - val_loss: 1.8304 - val_accuracy: 0.5754\n",
            "Epoch 185/200\n",
            "28709/28709 [==============================] - 7s 237us/step - loss: 0.3276 - accuracy: 0.8903 - val_loss: 1.9113 - val_accuracy: 0.5634\n",
            "Epoch 186/200\n",
            "28709/28709 [==============================] - 7s 233us/step - loss: 0.3266 - accuracy: 0.8891 - val_loss: 1.8821 - val_accuracy: 0.5692\n",
            "Epoch 187/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3215 - accuracy: 0.8904 - val_loss: 1.9134 - val_accuracy: 0.5737\n",
            "Epoch 188/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3290 - accuracy: 0.8893 - val_loss: 1.9391 - val_accuracy: 0.5793\n",
            "Epoch 189/200\n",
            "28709/28709 [==============================] - 7s 233us/step - loss: 0.3270 - accuracy: 0.8904 - val_loss: 1.9186 - val_accuracy: 0.5770\n",
            "Epoch 190/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3212 - accuracy: 0.8907 - val_loss: 1.8494 - val_accuracy: 0.5770\n",
            "Epoch 191/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.3265 - accuracy: 0.8890 - val_loss: 1.8476 - val_accuracy: 0.5759\n",
            "Epoch 192/200\n",
            "28709/28709 [==============================] - 7s 234us/step - loss: 0.3105 - accuracy: 0.8953 - val_loss: 1.8540 - val_accuracy: 0.5720\n",
            "Epoch 193/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.3183 - accuracy: 0.8948 - val_loss: 1.8499 - val_accuracy: 0.5720\n",
            "Epoch 194/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3212 - accuracy: 0.8941 - val_loss: 1.7718 - val_accuracy: 0.5659\n",
            "Epoch 195/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3231 - accuracy: 0.8917 - val_loss: 1.8237 - val_accuracy: 0.5673\n",
            "Epoch 196/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3103 - accuracy: 0.8961 - val_loss: 1.8884 - val_accuracy: 0.5740\n",
            "Epoch 197/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3093 - accuracy: 0.8963 - val_loss: 1.8844 - val_accuracy: 0.5698\n",
            "Epoch 198/200\n",
            "28709/28709 [==============================] - 7s 235us/step - loss: 0.3161 - accuracy: 0.8953 - val_loss: 1.9256 - val_accuracy: 0.5712\n",
            "Epoch 199/200\n",
            "28709/28709 [==============================] - 7s 236us/step - loss: 0.3106 - accuracy: 0.8966 - val_loss: 1.8527 - val_accuracy: 0.5701\n",
            "Epoch 200/200\n",
            "28709/28709 [==============================] - 7s 237us/step - loss: 0.3169 - accuracy: 0.8941 - val_loss: 1.9286 - val_accuracy: 0.5726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f87628168d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h2J8xBI7KEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving the  model to  use it later on\n",
        "fer_json = model.to_json()\n",
        "with open(\"gdrive/My Drive/fer.json\", \"w+\") as json_file:\n",
        "    json_file.write(fer_json)\n",
        "model.save_weights(\"gdrive/My Drive/fer.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rySCh7j8Bopp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZUTGd62CnfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load model\n",
        "model = model_from_json(open(\"gdrive/My Drive/fer.json\", \"r\").read())\n",
        "#load weights\n",
        "model.load_weights('gdrive/My Drive/fer.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ4FqJCSDHxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "face_haar_cascade = cv2.CascadeClassifier('gdrive/My Drive/haarcascade_frontalface_default.xml')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodSuD2kHg-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap=cv2.VideoCapture(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPc2WJBEHmfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while True:\n",
        "    ret,test_img=cap.read()# captures frame and returns boolean value and captured image\n",
        "    if not ret:\n",
        "        continue\n",
        "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
        "    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n",
        "    for (x,y,w,h) in faces_detected:\n",
        "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)\n",
        "        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image\n",
        "        roi_gray=cv2.resize(roi_gray,(48,48))\n",
        "        img_pixels = image.img_to_array(roi_gray)\n",
        "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
        "        img_pixels /= 255\n",
        "        predictions = model.predict(img_pixels)\n",
        "        #find max indexed array\n",
        "        max_index = np.argmax(predictions[0])\n",
        "        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
        "        predicted_emotion = emotions[max_index]\n",
        "        cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "\n",
        "    resized_img = cv2.resize(test_img, (1000, 700))\n",
        "    cv2.imshow('Facial emotion analysis ',resized_img)\n",
        "    if cv2.waitKey(10) == ord('q'):#wait until 'q' key is pressed\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfbPn_QBHpU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap.release()\n",
        "cv2.destroyAllWindows"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}